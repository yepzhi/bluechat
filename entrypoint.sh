#!/bin/bash

# Start Ollama in the background
echo "ğŸ¦™ Starting Ollama Server..."
ollama serve &

# Wait for Ollama to be ready
echo "â³ Waiting for Ollama to start..."
sleep 10

# Pull the requested model (Qwen 1.5B)
# 'qwen2.5:1.5b' is a great balance of speed/intelligence for CPU
MODEL_NAME="qwen2.5:1.5b"

echo "â¬‡ï¸  Pulling AI Model: $MODEL_NAME..."
ollama pull $MODEL_NAME

echo "âœ… Model ready!"

# Start Node.js Server
echo "ğŸš€ Starting Chatbot Server..."
npm start
